'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/faq/','title':"FAQ",'content':"Frequently Asked Questions Information about the Cluster  What are the available resources on the cluster? A table showing the hardware specifications for all nodes provided here. Who maintains the cluster? The cluster is administrated by Hans Viessmann (you can contact him via the contact form).  Getting Help  What help/support is available? No formal support is provided, other than basic adminstrative tasks and maintanence work. Users may contact the administrator for help, such as in the case of install/updating some hardware and/or software. Requests to create custom environments or other specialised tasks are not acceptable.  "});index.add({'id':1,'href':'/register/','title':"Register",'content':"Register To register, please read the Terms and Conditions and then fill out the form below and submit it. You should receive a response on the same day (within working hours) or latest next day.\nNOTE: not all requests to access the cluster will be accepted! Please consider the following questions, and use these as a guide to determine whether or not your reason to use the cluster is justified or appropriate:\n Does my application need access to high-performance/specialised hardware (e.g. NVIDIA K20, Intel Xeon Phi, etc.)? Does my application need to be run on multiple nodes (e.g. via MPI)? Is the software stack on the cluster appropriate for my application (e.g. SLURM batch management)? How long will the runtime of my application be (does it take an hour, or a day, or multiple weeks)?  _External Access: Heriot-Watt University impose very strict policies on their computer networks, specifically that critical hardware infrastructures are not exposed to the outside world. Thus, to access the cluster from outside the University requires that users make use of the University VPN \u0026mdash; members of staff (including PhD students) have access to this service already, everyone else will need to specifically request this. Please indicate this in the form below._\n"});index.add({'id':2,'href':'/docs/the-cluster/','title':"The Cluster",'content':"The Cluster The cluster is made up of 1 head node and 10 compute nodes. Of the compute nodes, 8 are AMD based systems while the other 2 are Intel based systems. Here is the following hardware stack for all of the nodes:\n   Node Type Node Name Processor RAM HDD (/tmp) Extra Components     Head Node robotarium AMD Opteron 6320 (8 cores) 64 GB 916 GB \u0026mdash;   AMD Compute Node gpu01, gpu02, gpu03, gpu04, gpu05, gpu06 4x AMD Opteron 6376 (64 cores) 512 GB 40 GB NVIDIA K20 GPU, (2x in gpu06)   AMD Compute Node (Large RAM) gpu07, gpu08 4x AMD Opteron 6376 (64 cores) 1024 GB 40 GB NVIDIA K20 GPU (only in gpu07), 2x NVIDIA Titan Xp GPUs (only in gpu08)   Intel Compute Node mic01, mic02 2x Intel Xeon E5-2650v2 (16 cores) 128 GB 40 GB \u0026mdash;   NVIDIA DGX1 Node dgx01 2x Intel Xeon E5-2698v4 (40 cores) 512 GB 440 GB (7 TB at /raid/scratch) 8x NVIDIA Tesla P100    In addition to the above listed nodes, there are also some special-purpose nodes \u0026mdash; specifically, the cluster has eight Intel MIC nodes:\n   Node Type Node Name Processor Onboard Memory Extra Components     Intel MIC Compute Units mic01-0, mic01-1, mic01-2, mic01-3, mic02-0, mic02-1, mic02-2, mic02-3 Intel Xeon Phi 5120D 8 GB \u0026mdash;    All of the nodes are connected by both a 1Gbps network and an InfiniBand 4x 10Gbps network. We support the full OFED stack.\nThe nodes are made available through the SLURM resource management system \u0026mdash; more information on queues can be found here.\nDetails about the OS and available software packages can be found on the software information page.\n"});index.add({'id':3,'href':'/docs/','title':"Docs",'content':""});index.add({'id':4,'href':'/docs/how-to/','title':"How To",'content':"How To Here we provide some guides for various aspects of using the Robotarium cluster. The most important ones are listed directly below \u0026mdash; it is a good idea to familiarise yourselves with these first. Please be aware that some of the guides here are hosted on other sites and will need you to navigate away from here.\nNote: this page is still being populated, if you feel that anything is missing or amiss please contact us and we'll update this page appropriately.\nBasics Accessing the Cluster The precise details of how to access the cluster are omitted from this site, please contact us for more information.\nThe cluster can only be accessed from within the Heriot-Watt University network. Users wishing to use it from outside the university will need to setup an SSH tunnel (see SSH Forwarding) or use the HW-VPN (please contact us to give you access. HW staff have VPN access per default (see the HW-VPN details).\n Notice There is a user portal website available for users to check the current load of the cluster, you'll need to login using your cluster account to access this. For the moment, the site is using a self-signed SSL certificate, as such you will likely need to set your browser to accept the certificate before you can access the site.\n SSH Forwarding  Notice This is only available for users with MACS (School of Mathematics and Computer Science) accounts. Otherwise you can try out the HW-VPN.\n As a quick introduction, a SSH tunnel is a secure method to transport other network protocols across network boundaries \u0026mdash; assuming of course that you can access the network over SSH in the first place. This is achieved by establishing a SSH connection between the client (yourself) and the remote server, and then encapsulating (tunnelling) other network protocols \u0026mdash; such as HTTP(S), FTP, and SSH \u0026mdash; into it. In this instance, we will use a tunnel to forward an SSH connection from inside the university network to your system.\nThe basic idea is that you can forward SSH connections, meaning that one tunnels a series of SSH connections over one or more relay hosts to connect to some server. Historically, there are several way of doing this (if your interested you can read about it here), but the easiest way to achieve this is by using the SSH ProxyCommand option and the -W flag. Together these provide a way to chain SSH connections together. An example of this on the command line would be:\n$ ssh -o ProxyCommand='ssh -W %h:%p \u0026lt;USER\u0026gt;@\u0026lt;IP of remote server\u0026gt;' \u0026lt;USER\u0026gt;@\u0026lt;IP of relay server\u0026gt; Within the ProxyCommand we specify the remote server and through the -W flag we state that we want the connection to be forwarded to the relay server \u0026mdash; this is given as the last argument of the SSH command.\nWe can simplify this by removing the need to write all that out by placing it the ~/.ssh/config file. The structure of this would then be:\nHost SERVER1 HostName 192.168.0.1 User someone IdentityFile ~/.ssh/id_rsa Host SERVER2 HostName 192.168.1.1 User someoneelse ProxyCommand ssh SERVER1 -W %h:%p  Then by calling ssh SERVER2 you automatically get the connection forwarded over SERVER1.\nSetting up Your Account The Module System The cluster provides many different software packages (see Software for details) through the Modules system. The basic commands to access and manage these software packages is:\n module list \u0026mdash; list loaded modules module avail \u0026mdash; list all available modules module load \u0026lt;module name\u0026gt; \u0026mdash; load a specific module module unload \u0026lt;module name\u0026gt; \u0026mdash; unload a specific module  Further commands can be found in the man-page \u0026mdash; man module.\nWhen you first login, you'll find that the default-environment module has been loaded \u0026mdash; this gives you access the SLURM batch-management system. To make changes to what modules are loaded automatically for you, use module initadd and module initrm to add entries for you. It is advised not include module purge within your .bashrc file unless you know what you are doing.\nMore details on how to use the modules system can be read up in the Modules section.\nQueueing System The cluster uses SLURM, or the Simple Linux Utility for Resource Management to manage user workloads. It is the only means by which to run applications on the cluster. A good resource to understand how to use it is through the quickstart guide.\nThe Queues In the table below is given the queues (or as they are referred to in SLURM \u0026mdash; the partitions). The queues are ordered in their priority, with amd-shortq having the highest priority. What this means is that jobs assigned to that queue will likely be allocated before jobs in other queues.\n   Name Time Limit Nodes Notes     amd-shortq 1 hour gpu01 default queue â€“ please take note of this!   amd-longq 7 days gpu02-gpu08    intel-shortq 1 hour mic01    intel-longq 7 days mic02, dgx01    specialq 30 days gpu01-gpu08, mic01-mic02, dgx01 only accessible on request!    If users need access to the specialq or have other needs, please contact us.\nMored details about our queues (partitions) can be found using sinfo. For example:\n# to get detailed information about the queues (include generic resources) $ sinfo -o \u0026#34;%15N %10c %10m %25f %24G\u0026#34; --partition=amd-shortq NODELIST CPUS MEMORY AVAIL_FEATURES GRES gpu07 64 1018366 gpu-host gpu:k20:1,gpu:k6000:1 gpu08 64 1018854 gpu-host gpu:xp:1 $ sinfo -o \u0026#34;%15N %10c %10m %25f %24G\u0026#34; --partition=amd-longq NODELIST CPUS MEMORY AVAIL_FEATURES GRES gpu[01-05] 64 515989 gpu-host gpu:k20:1 gpu06 64 515989 gpu-host gpu:k20:2 $ sinfo -o \u0026#34;%15N %10c %10m %25f %24G\u0026#34; --partition=intel-longq NODELIST CPUS MEMORY AVAIL_FEATURES GRES dgx01 80 515896 gpu-host gpu:p100:8 mic02 32 128906 (null) (null) Which jobs are currently running and which jobs are currently queued for execution can be inspected using the squeue command.\nRunning Programs The three most important SLURM commands for running code are srun, sbatch and scancel. They allow you to insert programs into the queues and to take them off queues again. They also allow you to specify your program's exact needs.\n Notice This is a heterogeneous cluster! Not all codes can be run on all nodes! The nodes gpu01-gpu08 have AMD-based CPUs, the nodes mic01-mic02 have INTEL-based CPUs. Both are i86 compatible but depending on the level of compiler optimisation your programs may only run one of these two architectures. Furthermore, your code may or may not expect a certain number or even version of GPU or a MIC to be available. If so, you need to make sure that you specify your needs as precisely as possible; otherwise, your code will fail to run or suffer poor performance!\n The four most important needs you can specify are:\n the number of nodes you want --nodes=\u0026lt;n\u0026gt; which nodes you do or do not want --nodelist=\u0026lt;name,name,...\u0026gt; / --exclude=\u0026lt;name,name,...\u0026gt; how many cpus you want -c\u0026lt;n\u0026gt; which resources (gpus) you want --gres=\u0026lt;gres,gres,...\u0026gt;  Example usage:\n# to run a command and have its output printed in the shell we use the `srun\u0026#39; command $ srun \u0026lt;...command...\u0026gt; \u0026lt;...args...\u0026gt; # another similar example to run an application on an AMD node in the `amd-longq\u0026#39; queue: $ srun --partition=amd-longq \u0026lt;...command...\u0026gt; \u0026lt;...args...\u0026gt; # or on three AMD nodes, but not on gpu04 or gpu05 $ srun --partition=amd-longq --nodes=3 --exclude=gpu04,gpu05 \u0026lt;...command...\u0026gt; \u0026lt;...args...\u0026gt; # if you want to use all cores on a two AMD nodes (2 nodes with 64 cores each!) $ srun --partition=amd-longq --nodes=2 -c64 \u0026lt;...command...\u0026gt; \u0026lt;...args...\u0026gt; # if you want to use two particular AMD nodes $ srun --partition=amd-longq --nodelist=gpu06,gpu07 \u0026lt;...command...\u0026gt; \u0026lt;...args...\u0026gt; # Note here that the use of `nodelist\u0026#39; implies a minimum number of nodes while # `exclude\u0026#39; does not impact on the number of nodes asked for! # If you want to use one AMD core with a single gpu for longer than 1 hour but you do not care # which node you use $ srun --partition=amd-longq --gres=gpu \u0026lt;...command...\u0026gt; \u0026lt;...args...\u0026gt; # Note here, that this blocks the gpu from being used by anyone else; so # please do only specify `--gres=gpu\u0026#39; if your code *actually does use* a gpu! #If you want to use a system that requires two \u0026#39;K20` gpus for less than 1 hour: $ srun --gres==gpu:k20:2 \u0026lt;...command...\u0026gt; \u0026lt;...args...\u0026gt; # to run in \u0026#39;batch\u0026#39; mode, we use the `sbatch\u0026#39; command # these examples are the same as those above sbatch --output=outfile \u0026lt;...command...\u0026gt; \u0026lt;...args...\u0026gt; sbatch --partition=amd-longq --output=outfile \u0026lt;...command...\u0026gt; \u0026lt;...args...\u0026gt; sbatch --partition=amd-longq --nodes=3 --exclude=gpu04,gpu05 --output=outfile \u0026lt;...command...\u0026gt; \u0026lt;...args...\u0026gt; sbatch --partition=amd-longq --nodes=2 -c64 --output=outfile \u0026lt;...command...\u0026gt; \u0026lt;...args...\u0026gt; sbatch --partition=amd-longq --nodelist=gpu06,gpu07 --output=outfile \u0026lt;...command...\u0026gt; \u0026lt;...args...\u0026gt; sbatch --partition=amd-longq --gres=gpu --output=outfile \u0026lt;...command...\u0026gt; \u0026lt;...args...\u0026gt; sbatch --gres=gpu:k20:2 --output=outfile \u0026lt;...command...\u0026gt; \u0026lt;...args...\u0026gt; # to view the current cluster usage we can look at the queues using `squeue\u0026#39; $ squeue # to cancel a batch job we can use the `scancel\u0026#39; command $ scancel \u0026lt;...job ID...\u0026gt; Modules Most of the software packages available are managed through a system of modules which contain both the software files and configuration information. These modules can be dynamically loaded and unloaded allowing for a great deal of flexibility \u0026mdash; this is especially useful for making use of different versions or builds of the same software. More information can be found on the project website.\nExample usage: $ module avail acml/gcc/64/5.3.1 acml/gcc/fma4/5.3.1 # and many many more modules $ module load cuda65/toolkit # this loads the CUDA SDK and toolkit $ module unload cuda65/toolkit # this unloads the module\nPersonal Modules It is possible to create one's own modules. The benefit of doing this is that the module system will handle your environment variables for you, as well as other configuration. Additionally, if for instance you have a dependency on a module for a piece of software to work, this can be encoded into the module file.\nThe first step is to create a .modulerc file your home directory, e.g. ~/.modulerc. File should contain the following:\n#%Module -*- tcl -*- ## get extra modules files... module use /home/\u0026lt;USERNAME\u0026gt;/.modules Replace \u0026lt;USERNAME\u0026gt; with your username. The module use directive points to a directory where all of your modules are to be found. The next step is to create a module. Assuming that you have created the ~/.modules directory, you can add a module file to the directory. The typical convention is to create a directory naming the software (e.g.~/.modules/mysoftware) and give the module file the version of the software as its name, e.g. ~/.modules/mysoftware/1.0.0.\nAn example of the content of a module file goes as follows:\n#%Module -*- tcl -*- #Helpful messages proc ModulesHelp { } { puts stderr \u0026#34;Thismodulesetsupaccesstosomething\u0026#34; } module-whatis \u0026#34;setsupaccesstosomething\u0026#34; prereq somethingelse # ensure that this module is loaded before hand conflict thatothermodule # ensure that this module is NOT loaded module load gcc # you can have the module load dependencies for you set root /home/\u0026lt;USERNAME\u0026gt;/install/location # a TCL variable setenv SOMEVERION 0.95 # set an environment variable append-path PATH $root/bin # append to $PATH append-path MANPATH $root/man # append to $MANPATH append-path LD_LIBRARY_PATH $root/lib # append to $LD_LIBRARY_PATH For more information on what to put in a module file, have a look at the man pages, e.g. man modulefile.\n"});index.add({'id':5,'href':'/docs/quick-start/','title':"Quick Start",'content':"Quick Start This guide provides a quick-n-dirty series of steps to get you started on the cluster. The guides assumes the following:\n you have an account on the cluster you have experience with Linux-based systems (especially the command line) you have a SSH public-private key pair  Alright then, lift off!\nAccessing the Cluster (SSH) TBC\n"});index.add({'id':6,'href':'/terms/','title':"Terms",'content':"Terms and Conditions Mains Points  No guarantee of service or quality is given; the cluster is provided as a free service to members and affiliates of the Edinburgh Centre for Robotics with regular maintenance done by a small group of volunteers. Nonetheless some effort is made to ensure continuous uptime and availability. Very limited support is given; we only have a few volunteers at hand to help, and who themselves are busy doing their own work. No backups are made of user data; users are expected to keep copies (on other systems or storage devices) of their work, we take no responsibility for any loss of user data! No guarantees are made regarding the availability of hardware resources; the cluster is setup in a first-come first-serve fashion, as such it is possible that you might find hardware resources that you want to use allocated to another user. The hardware resources are managed through a batch-queue system; any attempt at bypassing it is strictly forbidden and will result in your account being deactivated (possibly permanently). Any work done with the cluster that leads to a publication, or other output, must acknowledge it within that publication (and ideally reference it as well)!  These terms are subject to change at anytime, please check this page regularly!\nAcknowledgement Any use of the cluster that leads to a publication or other output must acknowledge the cluster as a resource within the output. A possible formulation of this for a conference article is:\n â€¦ we acknowledge our use of the Edinburgh Centre for Robotics\u0026rsquo; Robotarium Cluster located at Heriot-Watt University, provided through funding by Engineering and Physical Sciences Research Council (EPSRC) Centre for Doctoral Training in Robotics and Autonomous Systems through grant EP/L016834/1 â€¦\n Referencing In addition to the acknowledgement, you can directly reference the cluster as a resource for your publication:\n@misc{edinburgh_centre_for_robotics_2014_1455754, author = {Edinburgh Centre for Robotics}, title = {Robotarium Cluster}, month = nov, year = 2014, note = {{The cluster is part of the EPSRC Centre for Doctoral Training in Robotics and Autonomous Systems (RAS) in Edinburgh grant (EP/L016834/1) funded by The Engineering and Physical Sciences Research Council (EPSRC) (UK).}}, doi = {10.5281/zenodo.1455754}, url = {https://doi.org/10.5281/zenodo.1455754} } More details about the DOI registration can be at https://doi.org/10.5281/zenodo.1455754.\n"});index.add({'id':7,'href':'/contact-us/','title':"Contact Us",'content':"Contact Us If you can not find the answers you are looking for on this site or Google, please fill out the form below and we'll try to answer your query as soon as possible.\nSlack Chat The easiest way to get help from existing users and admin-staff is to use Slack. You will need to be invited to join the chat, so please fill out the form below and we'll invite you ðŸ˜„.\n"});index.add({'id':8,'href':'/','title':"About",'content':"About This is the internal documentation site for the ECR Robotarium Cluster at Heriot-Watt University. It is funded by the Centre for Doctoral Training in Robotics and Autonomous Systems and the Edinburgh Centre for Robotics.\nThe site provides the following information and facilities:\n How to register to gain access to the cluster How to use the cluster FAQ \u0026amp; support contact details The terms and conditions  Note: this site is still incomplete, more information will be added when it is needed. The most helpful thing to do is to send us questions, and we will post the response to those questions here.\nReferencing The cluster can be referenced within your publication or output directly via a DOI number, please see the here for BibTeX referencing details.\n"});index.add({'id':9,'href':'/categories/','title':"Categories",'content':""});index.add({'id':10,'href':'/tags/','title':"Tags",'content':""});})();